import torch

import math
class CosineScheduleWarmupLR:
    def __init__(self, optimizer, warmup_steps, start_lr, ref_lr, T_max, last_epoch=-1, final_lr=0.):
        self.optimizer = optimizer
        self.start_lr = start_lr
        self.ref_lr = ref_lr
        self.final_lr = final_lr
        self.warmup_steps = warmup_steps
        self.T_max = T_max - warmup_steps
        self._step = 0.
    def step(self):
        self._step += 1
        if self._step < self.warmup_steps:
            progress = float(self._step) / float(max(1, self.warmup_steps))
            new_lr = self.start_lr + progress * (self.ref_lr - self.start_lr)
        else:
            progress = float(self._step - self.warmup_steps) / float(max(1, self.T_max))
            new_lr = max(self.final_lr, self.final_lr + (self.ref_lr - self.final_lr) * 0.5 * (1. + math.cos(math.pi * progress)))
        for group in self.optimizer.param_groups:
            group['lr'] = new_lr
        return new_lr
class CosineScheduleWD:
    def __init__(self, optimizer, ref_wd, T_max, final_wd=0.):
        self.optimizer = optimizer
        self.ref_wd = ref_wd
        self.final_wd = final_wd
        self.T_max = T_max
        self._step = 0.
    def step(self):
        self._step += 1
        progress = self._step / self.T_max
        new_wd = self.final_wd + (self.ref_wd - self.final_wd) * 0.5 * (1. + math.cos(math.pi * progress))
        if self.final_wd <= self.ref_wd:
            new_wd = max(self.final_wd, new_wd)
        else:
            new_wd = min(self.final_wd, new_wd)
        for group in self.optimizer.param_groups:
            if ('WD_exclude' not in group) or not group['WD_exclude']: group['weight_decay'] = new_wd
        return new_wd

def main(crop_size=224, patch_size=14, device=['cpu','cuda'][torch.cuda.is_available()]):
    from multiblock_mask_collator import MaskCollator
    mask_collator = MaskCollator(input_size=crop_size, patch_size=patch_size, pred_mask_scale=[0.15,0.2], enc_mask_scale=[0.85,1.0], aspect_ratio=[0.75,1.5], nenc=1, npred=4, allow_overlap=False, min_keep=10)
    import torchvision
    transform = torchvision.transforms.Compose([torchvision.transforms.RandomResizedCrop(crop_size, scale=[0.3,1.0]), torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])  #No horizontal_flip color_distortion gaussian_blur @https://github.com/facebookresearch/ijepa/blob/main/src/transforms.py
    dataset = torchvision.datasets.ImageFolder(root='./data/cifar10_mini/', transform=transform)
    dataloader = torch.utils.data.DataLoader(dataset, collate_fn=mask_collator, sampler=None, batch_size=16, drop_last=True, pin_memory=True, num_workers=4, persistent_workers=False)  #No distribution_sampler

    import vision_transformer_encoder_predictor
    encoder = vision_transformer_encoder_predictor.__dict__[['vit_tiny','vit_small','vit_base','vit_large','vit_huge','vit_giant'][2]](img_size=[crop_size], patch_size=patch_size).to(device)
    predictor = vision_transformer_encoder_predictor.__dict__['vit_predictor'](num_patches=encoder.patch_embed.num_patches, embed_dim=encoder.embed_dim, predictor_embed_dim=384, depth=12, num_heads=encoder.num_heads).to(device)
    def init_weights(m):
        def no_grad_trunc_normal(tensor, mean=0.0, std=1.0, a=-2.0, b=+2.0):  #https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
            def norm_cdf(x):  #computes standard normal cumulative distribution function
                return (1. + math.erf(x / math.sqrt(2.))) / 2.
            with torch.no_grad():  #values are generated by using a truncated uniform distribution and then using the inverse CDF for the normal distribution
                l = norm_cdf((a - mean) / std)  #lower cdf values
                u = norm_cdf((b - mean) / std)  #upper cdf values
                tensor.uniform_(2 * l - 1, 2 * u - 1)  #uniformly fill tensor with values from [l, u], then translate to [2l-1, 2u-1]
                tensor.erfinv_()  #use inverse cdf transform for normal distribution to get truncated standard normal
                tensor.mul_(std * math.sqrt(2.))  #transform to proper std
                tensor.add_(mean)  #transform to proper mean
                tensor.clamp_(min=a, max=b)  #clamp to ensure it's in the proper range
                return tensor

        if isinstance(m, torch.nn.Linear):
            no_grad_trunc_normal(m.weight, std=0.02)
            if m.bias is not None:
                torch.nn.init.constant_(m.bias, 0)
        elif isinstance(m, torch.nn.LayerNorm):
            torch.nn.init.constant_(m.bias, 0)
            torch.nn.init.constant_(m.weight, 1.0)
    for m in encoder.modules():
        init_weights(m)
    for m in predictor.modules():
        init_weights(m)
    import copy
    target_encoder = copy.deepcopy(encoder)
    for p in target_encoder.parameters():
        p.requires_grad = False

    epochs = 10
    param_groups = [{'params': (p for n, p in encoder.named_parameters() if ('bias' not in n) and (len(p.shape) != 1))}, {'params': (p for n, p in predictor.named_parameters() if ('bias' not in n) and (len(p.shape) != 1))}, {'params': (p for n, p in encoder.named_parameters() if ('bias' in n) or (len(p.shape) == 1)), 'WD_exclude': True, 'weight_decay': 0}, {'params': (p for n, p in predictor.named_parameters() if ('bias' in n) or (len(p.shape) == 1)), 'WD_exclude': True, 'weight_decay': 0}]
    optimizer = torch.optim.AdamW(param_groups)
    ipe_scale = 1.0
    iterations_per_epoch = len(dataloader)
    learning_rate_scheduler = CosineScheduleWarmupLR(optimizer, warmup_steps=int(40*iterations_per_epoch), start_lr=0.0002, ref_lr=0.001, final_lr=0.000001, T_max=int(ipe_scale*epochs*iterations_per_epoch))
    weight_decay_scheduler = CosineScheduleWD(optimizer, ref_wd=0.04, final_wd=0.4, T_max=int(ipe_scale*epochs*iterations_per_epoch))

    ema = [0.996,1.0]
    momentum_target_encoder_scheduler = (ema[0] + i*(ema[1]-ema[0])/(iterations_per_epoch*epochs*ipe_scale) for i in range(int(iterations_per_epoch*epochs*ipe_scale)+1))

    for epoch in range(0, epochs):  
        for minibatch, (udata, masks_enc, masks_pre) in enumerate(dataloader):
            imgs = udata[0].to(device, non_blocking=True)
            masks_enc = [u.to(device, non_blocking=True) for u in masks_enc]
            masks_pre = [u.to(device, non_blocking=True) for u in masks_pre]

            learning_rate_scheduler.step()
            weight_decay_scheduler.step()

            with torch.no_grad():
                h = target_encoder(imgs)
                h = torch.nn.functional.layer_norm(h, (h.size(-1),))  # normalize over feature-dimension

                all_h = []
                for m in masks_pre:  #masks_pre: list of tensors containing indices of patches in [N] to keep
                    mask_keep = m.unsqueeze(-1).repeat(1, 1, h.size(-1))  #h: tensor of shape [B (batch-size), N (num-patches), D (feature-dim)]
                    all_h += [torch.gather(h, dim=1, index=mask_keep)]
                h = torch.cat(all_h, dim=0)

                B = len(h)
                h = torch.cat([torch.cat([h[i*B:(i+1)*B] for _ in range(len(masks_enc))], dim=0) for i in range(len(h)//B)], dim=0)

            p = encoder(imgs, masks_enc)
            z = predictor(p, masks_enc, masks_pre)
            loss = torch.nn.functional.smooth_l1_loss(z, h)

            loss.backward()    #No torch.cuda.amp.GradScaler().scale(loss).backward() for bfloat16
            optimizer.step()
            optimizer.zero_grad()

            with torch.no_grad():  #momentum update of target_encoder from context_encoder  #https://github.com/facebookresearch/ijepa/issues/25
                m = next(momentum_target_encoder_scheduler)
                for param_q, param_k in zip(encoder.parameters(), target_encoder.parameters()):
                    param_k.data.mul_(m).add_((1.0-m) * param_q.detach().data)

            print('epoch=%04d/%04d  minibatch=%04d  loss=%.4f'%(epoch,epochs, minibatch, loss.item()))

if __name__ == "__main__":
    main()

'''
# ubuntu-18.04  nvidia-cuda-11.*
conda create python=3.8 --name myjepa --no-default-packages
conda activate myjepa                                          #python -Bu jepa.py
pip install torch torchvision torchaudio
'''
